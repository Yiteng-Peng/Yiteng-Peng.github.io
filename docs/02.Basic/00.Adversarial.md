---
date: 2024-10-19 10:20:07
permalink: /pages/3bf3f25340d2
tags: 
  - adversarial
---

学习：<https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html> 所提及的基础论文。

### Foundation

1. Evasion attacks against machine learning at test time

这篇2013年的文章据说是第一个提出Adversarial Attack这个概念的，对这个问题定义得很清楚：

- 对于一个x，找到x'，使得降低损失函数g(x')的值尽可能小，进而使得分类器f(x)预测相反。
- x'可能是有限制的（例如输入是邮件文本时，你能改变的是文本而不能是像素）且希望x和x'的距离较小。
- 这里着重提出，损失函数在0附近时，似乎就不是很有价值（outside of the samples’ support）。

对于最后一点这个challenge，本文在正常的损失函数g(x)以外引入了一项惩罚项来计算x和其他同类x的距离，以保证x处于“densely populated regions”之中。

2. 